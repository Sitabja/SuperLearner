{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: The Super Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "from pandas.plotting import scatter_matrix\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Super Learner Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Super Learner* is a heterogeneous stacked ensemble classifier. This is a classification model that uses a set of base classifiers of different types, the outputs of which are then combined in another classifier at the stacked layer. The Super Learner was described in [(van der Laan et al, 2007)](https://pdfs.semanticscholar.org/19e9/c732082706f39d2ba12845851309714db135.pdf) but the stacked ensemble idea has been around for a long time. \n",
    "\n",
    "Figure 1 shows a flow diagram of the Super Learner process (this is from (van der Laan et al, 2007) and the process is also described in the COMP47590 lecture \"[COMP47590 2017-2018 L04 Supervised Learning Ensembles 3](https://www.dropbox.com/s/1ksx94nxtuyn4l8/COMP47590%202017-2018%20L04%20Supervised%20Learning%20Ensembles%203.pdf?raw=1)\"). The base classifiers are trained and their outputs are combined along with the training dataset labels into a training set for the stack layer classifier. To avoid overfitting the generation of the stacked layer training set uses a k-fold cross validation process (described as V-fold in Figure 1). To further add variety to the base estimators a bootstrapping selection (as is used in the bagging ensemble approach).\n",
    " \n",
    "![Super Learner Process Flow](SuperLearnerProcessFlow.png \"Logo Title Text 1\")\n",
    "Figure 1: A flow diagram for the Super Learner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the SuperLearnerClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class SuperLearnerClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "     criteria: str,'label'or'probability', default:'label'\n",
    "                  used to specify whether the stacked model input is a label prediction or probability predictions of base models\n",
    "        \n",
    "     stack_input: bool, default:False\n",
    "                     used to specify whether to add original input to the stack layer.\n",
    "        \n",
    "     stack_model : str, name of the model at the stack model, default:'CART'\n",
    "     base_models: list, list of base models, default:['LR','KNN','CART','SVC','NB','MLP']\n",
    "                     used to specify the list of base models to be used.\n",
    "                     \n",
    "     number_of_models: int, number of base models, default:6\n",
    "                          used to specify the number of base models\n",
    "        \n",
    "    Methods\n",
    "    ----------\n",
    "     fit(X,Y) : Fit the model according to the given training data.\n",
    "     \n",
    "     predict(X): Predict class labels for samples in X.\n",
    "     \n",
    "     predict_proba: Predict class probabilities for samples in X.\n",
    "     \n",
    "     get_predictive_power_base_models(): to get the accuracies of the base models on the training set of the Superlearner\n",
    "     \n",
    "     get_confusion_matrix_base_models(): to get the confusion matrices of the base learners on the training set of the Superlearner\n",
    "     \n",
    "     get_diversity_base_models() :  to get the diversity among the base models in terms of correlation coefficient, Q statistics \n",
    "                                 and disagreement measure\n",
    "    Attributes:\n",
    "    -------------\n",
    "    base_models_predictions : the list of predictions of the abse models.\n",
    "    \n",
    "    \n",
    "   Notes\n",
    "    -----\n",
    "    Number of base mdoels should be between 5 to 10.\n",
    "    The list of base models should be from the choice 7 base models : ['LR','KNN','CART','SVC','NB','MLP','RF']\n",
    "    If a list of base models are passed then Superlearners trains the base _models with default sensible hyper parameters.\n",
    "    if a dictionary of base models along with the hyper parameters are sent, it overwrites the default hyper parameters of \n",
    "    the base models.\n",
    "    \n",
    "    \n",
    "    See also\n",
    "    --------\n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = SuperLearnerClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self,criteria='label',stack_input=False, stack_model= 'CART',\n",
    "                 base_models=['LR','KNN','CART','SVC','NB','MLP'], number_of_models=6):\n",
    "                                                                            \n",
    "        \n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        criteria: str,'label'or'probability', default:'label'\n",
    "                  used to specify whether the stacked model input is a label prediction or probability predictions of base models\n",
    "        \n",
    "        stack_input: bool, default:False\n",
    "                     used to specify whether to add original input to the stack layer.\n",
    "        \n",
    "        base_models: list or dict, list of base models or dictionary of base models with their corresponding hyper parameters, default:['LR','KNN','CART','SVC','NB']\n",
    "                     used to specify the list of base models to be used.\n",
    "                     \n",
    "        number_of_models: int, number of base models, default:5\n",
    "                          used to specify the number of base models\n",
    "        Returns\n",
    "        -------\n",
    "        self: Object\n",
    "        \"\"\"\n",
    "        if criteria not in ['label','probability']:\n",
    "            raise ValueError('Unknown criteria',criteria);\n",
    "            return;\n",
    "            \n",
    "        if number_of_models < 5 or number_of_models > 10:\n",
    "            raise ValueError('Number of models should be 5 to 10');\n",
    "            return;\n",
    "        \n",
    "        if len(base_models) < 3:\n",
    "            raise ValueError('Number of models should be 5 to 10');\n",
    "            return;\n",
    "        \n",
    "        #default hyper parameter if no hyper parameter is used\n",
    "        best_parameters = {'CART': {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 50}, \n",
    "                           'RF': {'max_features': 4, 'min_samples_split': 25, 'n_estimators': 200}, \n",
    "                           'KNN': {'n_neighbors': 6}, \n",
    "                           'LR': {'C': 0.2, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}, \n",
    "                           'MLP': {'alpha': 1e-05, 'hidden_layer_sizes': (400, 200), 'solver':'lbfgs', 'activation':'logistic'}, \n",
    "                           'SVC': {'probability':True},\n",
    "                           'NB':{}\n",
    "                          }\n",
    "        \n",
    "        \n",
    "        self.base_models = base_models\n",
    "        self.criteria = criteria\n",
    "        self.stack_input = stack_input\n",
    "        self.stack_model = stack_model\n",
    "        self.base_models_predictions = []\n",
    "          \n",
    "        if(not isinstance(base_models, list)):\n",
    "            # overwrite the default parameters with the parameters passed in the base_models dictionary:\n",
    "            for model in self.base_models:\n",
    "                best_parameters[model] = self.base_models[model];\n",
    "            self.base_models = list(self.base_models.keys())\n",
    "        \n",
    "        self.models = []\n",
    "        self.number_of_models = number_of_models;\n",
    "        \n",
    "        #make a dictionary of model choices\n",
    "        models_choices_ = {}\n",
    "        models_choices_['LR'] = LogisticRegression(**best_parameters['LR'])\n",
    "        models_choices_['SVC'] = SVC(**best_parameters['SVC'])\n",
    "        models_choices_['KNN'] =  KNeighborsClassifier(**best_parameters['KNN'])\n",
    "        models_choices_['CART'] = DecisionTreeClassifier(**best_parameters['CART'])\n",
    "        models_choices_['NB'] = GaussianNB() #no hyper parameter to tune for Naive Bayes\n",
    "        models_choices_['RF'] = RandomForestClassifier(**best_parameters['RF'])\n",
    "        models_choices_['MLP'] = MLPClassifier(**best_parameters['MLP'])\n",
    "        \n",
    "        #get the actuale base models to be used in the superlearner based on the number of models and model choices\n",
    "        index = 0\n",
    "        for n in range(number_of_models):\n",
    "            if index == len(self.base_models):\n",
    "                index = 0\n",
    "            if self.base_models[index] not in models_choices_:\n",
    "                raise ValueError('Bad choice of model ',self.base_models[index])\n",
    "                return\n",
    "            else:\n",
    "                self.models.append(copy.deepcopy(models_choices_[self.base_models[index]]))\n",
    "            index+=1;\n",
    "            \n",
    "            \n",
    "        #stack layer model       \n",
    "        if(self.stack_model not in models_choices_):\n",
    "            raise ValueError('Bad choice of model ',self.stack_model)\n",
    "            return\n",
    "            \n",
    "       \n",
    "        self.final_stack_model = copy.deepcopy(models_choices_[self.stack_model])\n",
    "       \n",
    "        \n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"     \n",
    "        k = 10\n",
    "        each_fold_length = int(len(X)/k)\n",
    "        \n",
    "        # fold X and Y\n",
    "        sub_samples_X=[X[i:i+each_fold_length] for i in range(0,len(X),each_fold_length)]\n",
    "        sub_samples_y=[y[i:i+each_fold_length] for i in range(0,len(X),each_fold_length)]\n",
    "   \n",
    "        stacked_predictions = []\n",
    "        for i in range(0,len(sub_samples_X)):\n",
    "            # make the ith fold as test fold and remaining folds as training set\n",
    "            X_test = sub_samples_X[i];\n",
    "            X_train = [sub_samples_X[j] for j in range(0,len(sub_samples_X)) if j!=i]\n",
    "            y_test = sub_samples_y[i];\n",
    "            y_train = [sub_samples_y[j] for j in range(0,len(sub_samples_X)) if j!=i]\n",
    "            \n",
    "            #flatten the X_train and y_train to match the shape\n",
    "            X_train = list(itertools.chain.from_iterable(X_train))\n",
    "            y_train = list(itertools.chain.from_iterable(y_train))\n",
    "            \n",
    "            #fit the base models for the ith test_fold in k-fold\n",
    "            y_pred = []\n",
    "            for model in self.models:\n",
    "                model.fit(X_train,y_train)\n",
    "                #depending upon the criterian taking prediction label/ prediction probability from the trained base modls\n",
    "                if self.criteria == 'label':\n",
    "                    predicted_value = model.predict(X_test)\n",
    "                else:\n",
    "                    predicted_value = model.predict_proba(X_test)\n",
    "                y_pred.append(predicted_value.tolist())\n",
    "            \n",
    "            #stack the predicted output of the base models.\n",
    "            stacked_predictions.append(np.column_stack(y_pred).tolist())\n",
    "            \n",
    "            \n",
    "        # flatten the stacked_prediction to match the shape\n",
    "        stacked_predictions = list(itertools.chain.from_iterable(stacked_predictions))\n",
    "        \n",
    "        #base_models_predictions is stored to verify diversity among base models\n",
    "        self.base_models_predictions = np.column_stack(stacked_predictions)\n",
    "       \n",
    "        #depending upon the parameter the original input data is stacked\n",
    "        if(self.stack_input):\n",
    "            stacked_predictions = np.column_stack((X,stacked_predictions))\n",
    "       \n",
    "        #fit the stacked model \n",
    "        self.final_stack_model.fit(stacked_predictions,y)\n",
    "    \n",
    "        #train the base models again with the entire training set\n",
    "        for model in self.models:\n",
    "                model.fit(X,y)\n",
    "        #storing the y values to verify the predictive power of the base models\n",
    "        self.y = y\n",
    "        \n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        X_predict = []\n",
    "        for model in self.models:\n",
    "            if self.criteria == 'probability':\n",
    "                X_predict.append(model.predict_proba(X))\n",
    "            else:\n",
    "                X_predict.append(model.predict(X))\n",
    "                \n",
    "        stacked_predict = np.column_stack(X_predict).tolist()\n",
    "\n",
    "        if(self.stack_input):\n",
    "            stacked_predict = np.column_stack((X,stacked_predict))\n",
    "            \n",
    "       \n",
    "        final_predict = self.final_stack_model.predict(stacked_predict)\n",
    "        \n",
    "        return final_predict\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        X_predict = []\n",
    "        for model in self.models:\n",
    "            if self.criteria == 'probability':\n",
    "                X_predict.append(model.predict_proba(X).tolist())\n",
    "            else:\n",
    "                X_predict.append(model.predict(X).tolist())\n",
    "        stacked_predict = np.column_stack(X_predict)\n",
    "        if(self.stack_input):\n",
    "            stacked_predict = np.column_stack((X,stacked_predict))\n",
    "        final_predict = self.final_stack_model.predict_proba(stacked_predict)\n",
    "\n",
    "        return final_predict\n",
    "    \n",
    "    \"\"\"\n",
    "    We want the each base model to be a strong predictor\n",
    "    \"\"\"\n",
    "    def get_predictive_power_base_models(self):\n",
    "        \"\"\" Measure the predictive power of the base_models\n",
    "        Parameters\n",
    "        ----------\n",
    "        self : Object\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        predictive_power: A dictionary containing the accuracy score all the base models\n",
    "        \"\"\"\n",
    "        predictive_power = {}\n",
    "        for indx in range(len(self.base_models_predictions)):\n",
    "            predictive_power[self.base_models[indx]] = metrics.accuracy_score(self.y, self.base_models_predictions[indx])\n",
    "        return predictive_power\n",
    "    \n",
    "    def get_confusion_matrix_base_models(self):\n",
    "        confusion_matrics_dict = {}\n",
    "        for i in range(len(self.base_models)):\n",
    "            confusion_matrics_dict[self.base_models[i]] = pd.crosstab(np.array(self.y), self.base_models_predictions[i], rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)\n",
    "        return confusion_matrics_dict\n",
    "    \n",
    "    def get_pairwise_relation_(self,model1_predict,model2_predict):\n",
    "        \"\"\" Measure the number of agreements and disagreements between two models\n",
    "        Parameters\n",
    "        ----------\n",
    "        model1_predict , model2_predict : Number of predictions of two models\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A tuple containing (N00,N01,N10,N11)\n",
    "        \n",
    "        \"\"\"\n",
    "        N00 = 0\n",
    "        N01 = 0;\n",
    "        N10 = 0;\n",
    "        N11 = 0\n",
    "        for i in range(len(model1_predict)):\n",
    "            if(model1_predict[i] == y_train[i] and model2_predict[i] == y_train[i]):\n",
    "                N11 +=1\n",
    "            elif(model1_predict[i] == y_train[i] and model2_predict[i] != y_train[i]):\n",
    "                N10 += 1\n",
    "            elif(model1_predict[i] != y_train[i] and model2_predict[i] == y_train[i]):\n",
    "                N01 += 1\n",
    "            elif(model1_predict[i] != y_train[i] and model2_predict[i] != y_train[i]):\n",
    "                N00 += 1\n",
    "        return (N00,N11,N10,N01)\n",
    "    \n",
    "    def get_q_score_(self,N00,N11,N10,N01):\n",
    "        \"\"\" Measure the Q_Statistics between two models\n",
    "        Parameters\n",
    "        ----------  \n",
    "        NOO: Number of samples incorrectly predicted by model1 as well as model2 \n",
    "        N01: Number of samples incorrectly predicted by model1, but correctly predicted by model2\n",
    "        N10: Number of samples correctly predicted by model1, but incorrectly predicted by model2\n",
    "        N11: Number of sample correclt predicted by both the models\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        q_measure : Q_statistics measure\n",
    "        \n",
    "        \"\"\"\n",
    "        q_measure = (N00*N11 - N10*N01)/(N00*N11 + N10*N01)\n",
    "        return q_measure\n",
    "    \n",
    "    def get_corr_coef_(self,N00,N11,N10,N01):\n",
    "        \"\"\" Measure the Q_Statistics between two models\n",
    "        Parameters\n",
    "        ----------  \n",
    "        NOO: Number of samples incorrectly predicted by model1 as well as model2 \n",
    "        N01: Number of samples incorrectly predicted by model1, but correctly predicted by model2\n",
    "        N10: Number of samples correctly predicted by model1, but incorrectly predicted by model2\n",
    "        N11: Number of sample correclt predicted by both the models\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        corr_coeff : Correlation Coefficient\n",
    "        \n",
    "        \"\"\"\n",
    "        corr_coeff = (N00*N11 - N10*N01)/((N11+N10)*(N01+N00)*(N11+N01)*(N10+N00))**0.5\n",
    "        return corr_coeff\n",
    "    \n",
    "    def get_disagreement_measure_(self,N00,N11,N10,N01):\n",
    "        \"\"\" Measure the Q_Statistics between two models\n",
    "        Parameters\n",
    "        ----------  \n",
    "        NOO: Number of samples incorrectly predicted by model1 as well as model2 \n",
    "        N01: Number of samples incorrectly predicted by model1, but correctly predicted by model2\n",
    "        N10: Number of samples correctly predicted by model1, but incorrectly predicted by model2\n",
    "        N11: Number of sample correclt predicted by both the models\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dm : Disagreement measure\n",
    "        \n",
    "        \"\"\"\n",
    "        dm = (N01+N10)/(N00+N11+N10+N01)\n",
    "        return dm;\n",
    "    \n",
    "    \"\"\"\n",
    "        In any ensemble (eg.Superlearner) we want the classifiers to be weakly correlated to each other.\n",
    "        There are three measures are taken to find out the diversities among the model.\n",
    "        \n",
    "        The Q Statistics :\n",
    "            The Q statistics of two binary classifier outputs (correct/incorrect), yi and yk\n",
    "            Qi,k = (N11*N00 − N01*N10)/(N11*N00 + N01*N10) Classifiers that tend to recognize the same objects correctly will have positive\n",
    "            values of Q, and those which commit errors on different objects will render Q negative.\n",
    "        \n",
    "        The correlation coefficient ρ :\n",
    "            The correlation between two binary classifier outputs (correct/incorrect), yi and yk , is\n",
    "            ρi,k = (N11*N00 − N01*N10)/((N11 + N10)(N01 + N00)(N11 + N01)(N10 + N00))**0.5\n",
    "        \n",
    "        The disagreement measure:\n",
    "            It is the ratio between the number of observations on which one classifiervis correct and the other is incorrect to the total number of observations.\n",
    "            Disi,k = (N01 + N10) / (N11 + N10 + N01 + N00)\n",
    "            \n",
    "        NOO: Number of samples incorrectly predicted by model1 as well as model2 \n",
    "        N01: Number of samples incorrectly predicted by model1, but correctly predicted by model2\n",
    "        N10: Number of samples correctly predicted by model1, but incorrectly predicted by model2\n",
    "        N11: Number of sample correclt predicted by both the models\n",
    "        \n",
    "        ref : https://link.springer.com/content/pdf/10.1023%2FA%3A1022859003006.pdf\n",
    "        \n",
    "        \"\"\"\n",
    "    def get_diversity_base_models(self):\n",
    "        \"\"\" Measure the diversities among all the base models taking into acount their agreement and disagreement.\n",
    "        Parameters\n",
    "        ----------\n",
    "        self: Object\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        R : A tuple of dataframe containing pairwise Q_statistics, pairwise Correlation Coefficient, pairwise disagreement measure\n",
    "        \n",
    "        \"\"\"\n",
    "        corr_coef_matrix = {}\n",
    "        q_stat_matrix = {}\n",
    "        dm_matrix = {}\n",
    "        for i in range(len(self.base_models)):\n",
    "            list_of_corr_coef = []\n",
    "            list_of_q_stat = []\n",
    "            list_of_dm = []\n",
    "            for j in range(len(self.base_models)):\n",
    "                    model1 = self.base_models[i]\n",
    "                    model2 = self.base_models[j]\n",
    "                    model1_predictions = self.base_models_predictions[i]\n",
    "                    model2_predictions = self.base_models_predictions[j]\n",
    "                \n",
    "                    N00, N01, N10, N11 = self.get_pairwise_relation_(model1_predictions, model2_predictions)\n",
    "                    \n",
    "                    # get correlation coefficient \n",
    "                    list_of_corr_coef.append(self.get_corr_coef_(N00, N01, N10, N11))\n",
    "                    #get q_statistics\n",
    "                    list_of_q_stat.append(self.get_q_score_(N00, N01, N10, N11))\n",
    "                    #get disagreement measure\n",
    "                    list_of_dm.append(self.get_disagreement_measure_(N00, N01, N10, N11))\n",
    "            \n",
    "            corr_coef_matrix[self.base_models[i]] = list_of_corr_coef\n",
    "            q_stat_matrix[self.base_models[i]] = list_of_q_stat\n",
    "            dm_matrix[self.base_models[i]] = list_of_dm\n",
    "            \n",
    "        return (pd.DataFrame(OrderedDict(corr_coef_matrix),index=self.base_models), \\\n",
    "                pd.DataFrame(OrderedDict(q_stat_matrix),index=self.base_models), \\\n",
    "                pd.DataFrame(OrderedDict(dm_matrix),index=self.base_models))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the SuperLearnerClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the SuperLearnClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
       "        0.93333333,  0.93333333,  1.        ,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "clf = SuperLearnerClassifier() #using the default parameters\n",
    "iris = load_iris()\n",
    "clf.fit(iris.data, iris.target)\n",
    "clf.predict(iris.data)\n",
    "cross_val_score(clf, iris.data, iris.target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches (should be 5 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset for  training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59582</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9436</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>151</td>\n",
       "      <td>179</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "59582      9       0       0       0       0       0       0       0       0   \n",
       "5978       3       0       0       0       0       0       0       0      26   \n",
       "9436       3       0       0       0       0       0       0       0       1   \n",
       "30251      0       0       0       0       0       0       0       0       0   \n",
       "2103       5       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "59582       0    ...            0         0         0         0         0   \n",
       "5978       84    ...           83         0         0         0         0   \n",
       "9436        0    ...           93        30         9         0         0   \n",
       "30251       0    ...          152       151       179       170         0   \n",
       "2103        0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "59582         0         0         0         0         0  \n",
       "5978          0         0         0         0         0  \n",
       "9436          0         0         0         0         0  \n",
       "30251         0         1         0         0         0  \n",
       "2103          0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform data pre-processing and manipulation as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,1:].values\n",
    "Y = np.array(dataset[\"label\"])\n",
    "X = X/255 #normalise the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into **trainnig set , validation set and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "    = train_test_split(X, Y, random_state=0, \\\n",
    "                                    train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X_train_plus_valid, \\\n",
    "                                        y_train_plus_valid, \\\n",
    "                                        random_state=0, \\\n",
    "                                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid serach on base learners to get the sensible hyper parameters for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red' style=\"font-style:italic\"> Grid Search on Decision tree</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
    "             'max_depth': list(range(3, 50, 3)), \\\n",
    "             'min_samples_split': [100]} #setting min_split as 10% of the dataset\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(DecisionTreeClassifier(), \\\n",
    "                                param_grid, cv=cv_folds, \\\n",
    "                            return_train_score=True)\n",
    "\n",
    "my_tuned_tree.fit(X_train, y_train)\n",
    "best_params['CART'] = my_tuned_tree.best_params_\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red' style=\"font-style:italic\"> Grid Search on Random Forest</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 6, 'min_samples_split': 100, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 501, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': [100] }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, y_train)\n",
    "\n",
    "best_params['RF'] = my_tuned_model.best_params_\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' style=\"font-style:italic\"> Grid Search on Logistic Regression</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 0.6, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'multi_class': ['ovr'], \n",
    " 'C': [x / 10.0 for x in range(2, 21, 2)],\n",
    " 'solver':['liblinear'],\n",
    "  'max_iter':[1000]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, y_train)\n",
    "best_params['LR'] = my_tuned_model.best_params_\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' style=\"font-style:italic\"> Grid Search on KNN</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 6}\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, y_train)\n",
    "\n",
    "best_params['KNN'] = my_tuned_model.best_params_\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' style=\"font-style:italic\"> Grid Search on Multi Layer Perception</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (400, 200, 100)}\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(MLPClassifier(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, y_train)\n",
    "\n",
    "best_params['MLP'] = my_tuned_model.best_params_\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' style=\"font-style:italic\"> Grid Search on Support Vector Machine</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(SVC(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train, y_train)\n",
    "\n",
    "best_params['SVC'] = my_tuned_model.best_params_\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CART': {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 300}, 'RF': {'max_features': 2, 'min_samples_split': 200, 'n_estimators': 300}, 'KNN': {'n_neighbors': 6}, 'LR': {'C': 0.6, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}, 'MLP': {'alpha': 0.01, 'hidden_layer_sizes': (400, 200, 100)}, 'SVC': {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}}\n"
     ]
    }
   ],
   "source": [
    "# printing the best parameters:\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate a Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Super Learner Classifier using the prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(base_models=['CART', 'RF', 'KNN', 'LR', 'MLP', 'NB'],\n",
       "            criteria='label', number_of_models=5, stack_input=False,\n",
       "            stack_model='CART')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the superlearner with default best hyperparameters found in the previous step\n",
    "base_models={'CART': {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 100}, \n",
    "             'RF': {'max_features': 2, 'min_samples_split': 200, 'n_estimators': 300}, \n",
    "             'KNN': {'n_neighbors': 6}, \n",
    "             'LR': {'C': 0.6, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}, \n",
    "             'MLP': {'alpha': 0.01, 'hidden_layer_sizes': (400, 200, 100)}, \n",
    "             'NB':{}}\n",
    "\n",
    "clf = SuperLearnerClassifier(base_models=base_models)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' style=\"font-style:italic\">**Evaluate the trained classifier**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75        48\n",
      "          1       0.94      0.91      0.92        64\n",
      "          2       0.62      0.86      0.72        74\n",
      "          3       0.75      0.77      0.76        56\n",
      "          4       0.90      0.57      0.70        75\n",
      "          5       0.89      0.96      0.93        53\n",
      "          6       0.58      0.58      0.58        65\n",
      "          7       0.91      0.98      0.94        43\n",
      "          8       0.95      0.85      0.90        61\n",
      "          9       1.00      0.90      0.95        61\n",
      "\n",
      "avg / total       0.82      0.81      0.81       600\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>103</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1    2   3   4   5   6   7   8   9  All\n",
       "True                                                   \n",
       "0          37   0    2   2   0   0   5   0   2   0   48\n",
       "1           0  58    3   3   0   0   0   0   0   0   64\n",
       "2           2   0   64   0   2   0   5   0   1   0   74\n",
       "3           2   2    3  43   2   0   4   0   0   0   56\n",
       "4           0   0   15   7  43   0  10   0   0   0   75\n",
       "5           0   0    0   0   0  51   0   2   0   0   53\n",
       "6          10   0   14   2   1   0  38   0   0   0   65\n",
       "7           0   0    0   0   0   1   0  42   0   0   43\n",
       "8           0   2    2   0   0   1   4   0  52   0   61\n",
       "9           0   0    0   0   0   4   0   2   0  55   61\n",
       "All        51  62  103  57  48  57  66  46  55  55  600"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.815555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.85      0.83        75\n",
      "          1       0.98      0.93      0.96        92\n",
      "          2       0.64      0.83      0.72       115\n",
      "          3       0.79      0.79      0.79        91\n",
      "          4       0.79      0.51      0.62        90\n",
      "          5       0.90      0.97      0.93        87\n",
      "          6       0.56      0.58      0.57        85\n",
      "          7       0.92      0.93      0.93        87\n",
      "          8       0.97      0.87      0.92        76\n",
      "          9       0.94      0.88      0.91       102\n",
      "\n",
      "avg / total       0.82      0.82      0.81       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>151</td>\n",
       "      <td>91</td>\n",
       "      <td>58</td>\n",
       "      <td>93</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>68</td>\n",
       "      <td>96</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1    2   3   4   5   6   7   8   9  All\n",
       "True                                                   \n",
       "0          64   0    3   3   0   0   5   0   0   0   75\n",
       "1           1  86    2   3   0   0   0   0   0   0   92\n",
       "2           0   0   96   0   4   0  14   0   1   0  115\n",
       "3           4   2    0  72   4   0   9   0   0   0   91\n",
       "4           0   0   28  10  46   0   6   0   0   0   90\n",
       "5           0   0    0   0   0  84   0   2   0   1   87\n",
       "6          11   0   18   3   3   0  49   0   1   0   85\n",
       "7           0   0    0   0   0   2   0  81   0   4   87\n",
       "8           0   0    4   0   1   0   4   0  66   1   76\n",
       "9           0   0    0   0   0   7   0   5   0  90  102\n",
       "All        80  88  151  91  58  93  87  88  68  96  900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Experiment (Task 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a 10-fold cross validation experiment to evaluate the performance of the SuperLearnerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score [ 0.84579439  0.77102804  0.79439252  0.77358491  0.80952381  0.80382775\n",
      "  0.82692308  0.8115942   0.7961165   0.74271845]\n",
      "Mean 0.797550365093\n",
      "Standard Deviation 0.0280474330894\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_train_plus_valid, y_train_plus_valid, cv=10)\n",
    "print('Score',scores)\n",
    "print('Mean' , scores.mean())\n",
    "print('Standard Deviation',scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance of Different Stack Layer Approaches (Task 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of the ensemble when a label based stack layer training set and a probability based stack layer training set is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Desicion Tree label': 0.80000000000000004,\n",
       " 'Desicion Tree probability': 0.80222222222222217,\n",
       " 'Logistic Regression label': 0.44222222222222224,\n",
       " 'Logistic Tree probability': 0.82666666666666666}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_accuracy_comparisons = dict()\n",
    "#label Desicion tree\n",
    "clf_desicion_label = SuperLearnerClassifier(criteria='label')\n",
    "clf_desicion_label.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "y_pred_desicion_label = clf_desicion_label.predict(X_test)\n",
    "\n",
    "# label logistic regression\n",
    "clf_logistic_label = SuperLearnerClassifier(criteria='label',stack_model='LR')\n",
    "clf_logistic_label.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "y_pred_logistic_label = clf_logistic_label.predict(X_test)\n",
    "\n",
    "#probability desicion tree\n",
    "clf_desicion_prob = SuperLearnerClassifier(criteria='probability')\n",
    "clf_desicion_prob.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "y_pred_desicion_prob = clf_desicion_prob.predict(X_test)\n",
    "\n",
    "#probability logistic regression\n",
    "clf_logistic_prob = SuperLearnerClassifier(criteria='probability',stack_model='LR')\n",
    "clf_logistic_prob.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "y_pred_logistic_prob = clf_logistic_prob.predict(X_test)\n",
    "\n",
    "# measure the accuracies\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_desicion_label)\n",
    "classifier_accuracy_comparisons['Desicion Tree label'] = accuracy\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_logistic_label)\n",
    "classifier_accuracy_comparisons['Logistic Regression label'] = accuracy\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_desicion_prob)\n",
    "classifier_accuracy_comparisons['Desicion Tree probability'] = accuracy\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_logistic_prob)\n",
    "classifier_accuracy_comparisons['Logistic Regression probability'] = accuracy\n",
    "\n",
    "# Print performance details\n",
    "display(classifier_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAD8CAYAAAC8YDc1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG5pJREFUeJzt3X2YXlV97vHv3YR3MFGBXhGLUYgWEYgQqFqlFDlYoS2g\nVFELiLSIFA7WlmOqtkoP9mDxBSn1RKTIiwU5WESLSApSkZcgJBoSwIKKVEGPVNEcRbQQfuePZ03z\nMM5knplMZnbC93NdubJn77XX/u0VmHvW2ntmUlVIkqRu+ZXpLkCSJP0yA1qSpA4yoCVJ6iADWpKk\nDjKgJUnqIANakqQOMqAlSeogA1qSpA4yoCVJ6qCZ012ANhzbbrttzZ07d7rLkKQNyrJly35QVduN\n9zwDWgObO3cuS5cune4yJGmDkuTfJ3KeS9ySJHWQAS1JUgcZ0JIkdZABLUlSBxnQkiR1kAEtSVIH\nGdCSJHWQAS1JUgf5g0o0sJUPrGLuws9NdxmSNhL3nX7wdJfQac6gJUnqIANakqQOMqAlSeogA1qS\npA4yoCVJ6iADWpKkDjKgJUnqIANakqQOMqAlSeogA1qSpA4yoCVJ6iADWpKkDjKgJUnqIANakqQO\nMqAlSeogA1qSpA6aUEAn+em6XjjJM5J8ai3HZyc5YdD2w879+yTLk9yV5JG2vTzJ4eta92RLcn+S\n2eNof1qSt46w/9eSXNq2D0hyRds+LMkpbftVSX59smqXJK0/M6frwlX1XWBtgTkbOAH4yIDt+/v+\nE4Akc4Erq2r+SO2SzKyqxwavemKSzKiq1evzGlX1HeC1I+z/dN+HrwIeB/5tfdYiSVp3k7bEnWRu\nkuuSrEjyhSQ7tv07Jbklyco2+/tpX/s72vauSW5ts9wVSeYBpwM7tX1nDGs/I8n7k9zR2p80jjpv\nTPKhJEuBE5P8apLLkyxtNbyotds6yflt31eT/N4IfR2Q5F+TfD7J3W3mniQzk/w4yZlJVgD7JDmw\n3cvKJB9LsmlfV3/R9n85yXNa34e0j7+a5F+SbN/X/oVtTL+e5E2t/c5Jlo9Q4x+1Ol4GHAR8qNXx\nvCS39bXbJcmtg46jJGn9msxn0H8HXFBVuwP/CJzV9n8Y+HBV7QbcP8q5x7c284EFrd1C4JtVNb+q\nThnW/jhgLjC/73rjMaOqFlTVma3Ov62qBcBrgHNbm78Crq6qfYD9gQ8k2XyEvn4DeAvwfGAX4JC2\nfxbwpVbf7cB5wKvbOGzZ7mHIQ23/R4EPtn1fAl5UVS8ELgf+rK/9bsB+wG8Cf53kV8e64aq6AbgK\n+NM2pncDjyR5QWtyDPDxsfqRJE2NyQzoFwMXt+2LgJf27b+sbV88/KRmCfCOJG8HnlVVj4xxrQOA\njw4tT1fVQ+Os9dJhfS1qs88rgKcm2QI4EHhn2/+vwObAjiP0dUtV3deWsD/Jmvv+T2BoeXkX4J6q\n+mb7+EJg374+Lml//yPwkra9I/AvSVYCbwN27Wt/RVX9vKoepBfkew9+60/wD8AxSWYCf9BXx39J\nclxbXVi6+merJngZSdJ4deIt7qq6GPh94BHgqiT7r+dLPty3HWCfNqucX1U7tC8QAhzat3/Hqrpn\npPJH+fiRqhp+bDQjtft74ENtZn0CvS8QxrrmeF0G/C69sV9SVT/+pcKqzmmrDQtmbDlrgpeRJI3X\nZAb0zcARbfsNwA1t+xbg1W37iOEnAbTnrvdW1VnAZ4DdgZ8A24xyrWuAN7eZH0metg51Xwv8SV8t\nQy+ULQZO6tv/wlHOf1GSHZPMoLdEfuMIbb4GzBt6vgz8IXB93/Ghl7teB9zUtmcBDyQJcPSw/g5N\nslmS7YCXAUvXcn/9njCmVfUz4DrgbFzelqROmWhAb9m+PWjoz9vohdkx7aWoI4GTW9u3Am9r+3cG\nRlonfQ1wR1tOfgFwYVX9ELipvQh2xrD25wLfBlYkuR14/QTvA3rh/JvtZbO7gD9u+08Ftmovb90J\nvGeU828FFgF3AXcDnx3eoAXhscDlbcn6F8DH+pps28bnLax51vweekvktwHfH9blHfQC/mbg3VU1\n/PhoLqH3KGF5e8MdesvqjwJfGLAPSdIUyOCrsBO8QLIlbbk3yRHA66rqkLHO2xAkOQA4saoOne5a\nJirJQmCzqjp1rLabzZlXc44+cwqqkvRkcN/pB093CVMiybL2IvK4TMX3Qe8FnN2Wan8MvGkKrqkB\nJPln4NfovaUuSeqQ9R7Q7dt79ljf15kOVXUtvWfYG6Sq+qXv7ZYkdUMn3uKWJElPZEBLktRBBrQk\nSR1kQEuS1EEGtCRJHWRAS5LUQQa0JEkdZEBLktRBBrQkSR1kQEuS1EEGtCRJHWRAS5LUQQa0JEkd\nZEBLktRBU/H7oLWR2G2HWSx9kvyCdUmabs6gJUnqIANakqQOMqAlSeogA1qSpA4yoCVJ6iADWpKk\nDjKgJUnqIANakqQOMqAlSeogf5KYBrbygVXMXfi56S5D0gbiPn/y4DpxBi1JUgcZ0JIkdZABLUlS\nBxnQkiR1kAEtSVIHGdCSJHWQAS1JUgcZ0JIkdZABLUlSBxnQkiR1kAEtSVIHGdCSJHWQAS1JUgcZ\n0JIkdZABLUlSBxnQkiR10JgBnWR1kuVJ7kxye5I/SzKhYE9yVZLZazl+fJKjJtJ3Xx+7tXqXJ3ko\nybfa9rXr0u/6kOSPkpw5jvYzk/x4lGPvTfLbbfvGJPPb9uIk2yR5WpLjJ6dySdL6NnOANo9U1dAn\n++2Bi4GnAO8e78Wq6qAxji8ab58j9LESGKr3fODKqvrU8HZJZlbVY+t6vbFM1XWq6p2j7H9Fq2Nn\n4HhgncdYkrT+jWsmXFUPAscBJ6ZnRpIzktyWZEWSNwMkmZPkS23mekeSl7X99yXZtm0f1c65PclF\nbd97kvx5256f5JbW5tNJntr2fzHJ+5LcmuSeob4HkeSAdv6VwMq27+jW1/IkHxlaHUjyyiRLknwl\nyaVJthqhvxuTnNnOXZlkQdt/WpILk9wEnJ9kiyQXtDZfSbJvXzfPSnJ9kq8neVdf3/+cZFlbufij\nYdc9q+2/JsnT275PJDl0hBrvb6sWpwPPa7WenuTiJL/b1+7SJAcPOpaSpPVr3EvVVXUvMAPYHjgW\nWFVVewN7A3+c5NnA64HFbea9B7C8v48kuwLvAvavqj2Ak0e41IXA26tqd3ph2j9jn1lV+wBvZfwz\n+QXACVW1S5IXAIcBL2m1zgSOaCsFC4GXV9WewIpRagTYrJ17MnBu3/5fb+f/IfDfgV9U1W7AkcBF\nSTZt7fYBDqU363/90NI0cHRV7UVvXN829AUKMAu4qap2BZYAfzngfS8E7q6q+VW1EPgH4I0Are+9\ngasH7EuStJ4NssS9NgcCuyc5vH08C5gH3Aacl2QT4IqqWj7svP2By6rqBwBV9VD/wSSzgNlVdX3b\ndQFwWV+Ty9vfy4C546x5SVV9u20fQC+YliYB2AL4DvAz4PnAzW3/psCNo/R3SbuH65Jsn2Trtv8z\nVfXztv1S4IzW7s4k3wV2bscWV9WP2n1f0douB/40ye+3Ns8Edmr7H2PNWHyC3iOHibgOOLvNwF8H\n/J+qWj28UZLj6K2aMOMp203wUpKk8Rp3QCd5DrAaeBAIcFJVLR6h3b7AwfSWeD9YVReua7F9ftH+\nXs347+Hhvu0A51XVE2ahSQ4Drq6qIwfor0b5+OHhDQc9P8kBwL7Ai6rqkSQ3ApsPeP5gF62qJJ+g\nt9pxNPCGUdqdA5wDsNmceRO6liRp/Ma1xJ1kO3ovGZ1dVQUsBt7SZsokeW6SrZI8C/h+VX2M3rLv\nnsO6ug74g77np0/rP1hVq4Af9T1fPhK4nsl3LfCavufiT0+yI3Az8FvtixHaPc0bpY/Xtjb70bvn\nkYL5BloAJtkFmAN8ox07MMnsJFsChwA30VuJeKiF8670ZvlDZgKvatuvZ/SZ/XA/AbYZtu/jwCn0\nlt/vHrAfSdIUGGT2uUWS5cAm9JZXLwI+2I6dS2+J+SvprQX/B73nqfsBpyR5FPgp8IRvnWrLvO8F\nrk+yGvgq7Xlon6OBRS247gWOGe/NjaWqViY5Fbi2vRz2KHB8Vd2W5Fjg0r5nxe8Avj5CN4+28Zmx\nlhr/DvhokpXtGkdV1X+25fPbgM8AzwAuqKrlSf4NOC7JXcDdwJf7+loFvKzV/T3aFwgD3Ov320tn\nK4HPVdXCqvpuknuATw7ShyRp6qQ3EdZEtKXnE0d4xr5BaG+mrwT2qKqfjNV+sznzas7RA3/btqQn\nuftO9xtDAJIsq6oF4z3PnyT2JJXkFcDXgA8NEs6SpKm1rm9xP6lV1Uunu4aJai/27TjddUiSRuYM\nWpKkDjKgJUnqIANakqQOMqAlSeogA1qSpA4yoCVJ6iADWpKkDjKgJUnqIANakqQOMqAlSeogA1qS\npA4yoCVJ6iADWpKkDjKgJUnqIH/dpAa22w6zWOovYJekKeEMWpKkDjKgJUnqIANakqQOMqAlSeog\nA1qSpA4yoCVJ6iADWpKkDjKgJUnqIANakqQO8ieJaWArH1jF3IWfm+4ytJG4z59KJ62VM2hJkjrI\ngJYkqYMMaEmSOsiAliSpgwxoSZI6yICWJKmDDGhJkjrIgJYkqYMMaEmSOsiAliSpgwxoSZI6yICW\nJKmDDGhJkjrIgJYkqYMMaEmSOsiAliSpgwYK6CQ/XdcLJXlGkk+t5fjsJCcM2n6E889P8q0ky5Pc\nnuTl61rzZEpyfJKjJqGfuUnuGKPNfkmuHGe/X0yyYN2qkyRNlimbQVfVd6vq8LU0mQ2cMI72Izml\nquYDbwUWTaDMX5Jk5mT0U1WLqurCyehLkrTxm3BAt5ncdUlWJPlCkh3b/p2S3JJkZZLThmbf/TO/\nJLsmubXNdlckmQecDuzU9p0xrP2MJO9Pckdrf9IY5S0Bduirda8k1ydZlmRxkjlt/96tv6FrDl3v\njUk+m+Q64Att3ylJbmvtT237tkryuTZjvyPJa9v+05Pc1dq+v+17T5I/b9vz2xitSPLpJE9t+7+Y\n5H1tbO5J8rIB/g1uSPKV9uclfYef0mq7O8miJL/SzjkwyZLW/rIkW48xlpKkabAuM+i/Ay6oqt2B\nfwTOavs/DHy4qnYD7h/l3ONbm/nAgtZuIfDNqppfVacMa38cMBeY33e9tfkd4AqAJJu0Wg+vqr2A\n84D3tnYfB97c6lg9rI892zm/leRAYB6wDzAf2CvJvu06362qParqBcDVSZ4OHAbs2mo9bYT6LgTe\n3o6vBN7dd2xmVe1DbxXg3SOc2+9B4L9V1Z7Aa1nzb0Cr9STg+cBOwKuSbAu8CzignbMUeNsY15Ak\nTYN1Wb59MfCqtn0R8Ld9+w9t2xcD7x/h3CXAO5M8E7i8qr6eZG3XOgBYVFWPAVTVQ6O0OyPJ3wDP\nbHUAPA94AXBNu8YM4HtJZgPbVNWSvlp/t6+va/quc2D789X28db0AvsG4ANJ3gdcWVU3tCXxnwP/\n0J4DP+FZcJJZwOyqur7tugC4rK/J5e3vZfS+KFmbTYCzkwx9gfHcvmO3VtW97ZqXAC9tdT0fuKmN\nxab0/i1GleQ4el8gMeMp241RjiRpskzK89XxqqqLk3wZOBi4KsmbgXsnoetTqupTbQn8PGAvIMCd\nVfXi/oYtoNfm4f7mwP+qqo8Ob5RkT+Ag4LQkX6iqv06yD/By4HDgRGD/cdzDL9rfqxn73+dPge8D\ne9BbDfl537Ea1rbafVxTVa8btJiqOgc4B2CzOfOG9ylJWk/WZYn7ZuCItv0GerNJgFuAV7ftI4af\nBJDkOcC9VXUW8Blgd+AnwDajXOsa4M1DL2wledoYtZ0N/EqSVwB3A9sleXE7d5Mku1bVj4GfJPmN\ntdXaLAbeNPS8NskOSbZP8gzgZ1X1CeAMYM/WZlZVXUUvQPfo76iqVgE/6nu+fCRwPRMzC/heVT3e\n+pnRd2yfJM9uz55fC9xI79/mN5Ps3O5jqyTPHd6pJGn6DTqD3jJJ//PkD9J7vvnxJKcA/wEc0469\nFfhEkncCVwOrRujvNcCRSR4F/i/wN1X1UJKb2otanwf+vq/9ufSWb1e0cz5GL4RHVFWV5DTgf1TV\n4iSHA2e15eWZwJnAncCxwMeSPE4vJEeqlar6lyS7AEva0vBPgT8Edqa3rP448CjwFnpfZHwmyeb0\nZqwjPeM9GliUZEt6KwfHjNBmEB8B/im9b9+6mifO+m+jN0Y7A/8KfLqqHk/yRuCSJJu1du8C7png\n9SVJ60mqJnfVsoXOIy0kjwBeV1WHTOpFJkmSratq6C3zhcCcqjp5msvqrM3mzKs5R5853WVoI3Hf\n6QdPdwnSlEiyrKrG/XMm1scz6L3ovbgU4MfAm9bDNSbLwUn+gt44/DvwxuktR5KknkkP6Kq6gWHP\nXbuqqi4FLp3uOiRJGs6fxS1JUgcZ0JIkdZABLUlSBxnQkiR1kAEtSVIHGdCSJHWQAS1JUgcZ0JIk\ndZABLUlSBxnQkiR1kAEtSVIHGdCSJHWQAS1JUgcZ0JIkddD6+H3Q2kjttsMslp5+8HSXIUlPCs6g\nJUnqIANakqQOMqAlSeogA1qSpA4yoCVJ6iADWpKkDjKgJUnqIANakqQOMqAlSeogf5KYBrbygVXM\nXfi56S5D0gbgPn/q4DpzBi1JUgcZ0JIkdZABLUlSBxnQkiR1kAEtSVIHGdCSJHWQAS1JUgcZ0JIk\ndZABLUlSBxnQkiR1kAEtSVIHGdCSJHWQAS1JUgcZ0JIkdZABLUlSBxnQkiR1UCcDOsnqJMuT3Jnk\n9iR/lmRCtSa5KsnstRw/PslRE68WkuzW6l2e5KEk32rb165Lv6Nc6xNJDh2jzY1J5o+jzwOSXLHu\n1UmSJsvM6S5gFI9U1XyAJNsDFwNPAd493o6q6qAxji+aUIVP7GMlMFTv+cCVVfWp4e2SzKyqx9b1\nepKkjV8nZ9D9qupB4DjgxPTMSHJGktuSrEjyZoAkc5J8qc1c70jysrb/viTbtu2j2jm3J7mo7XtP\nkj9v2/OT3NLafDrJU9v+LyZ5X5Jbk9wz1Pcg2uz0i0muBFa2fUe3vpYn+cjQ6kCSVyZZkuQrSS5N\nstUYfZ/axuGOJIuSpO/wG1v/K5MsaO23TnJ+u/ZXk/zeoPchSZpanQ9ogKq6F5gBbA8cC6yqqr2B\nvYE/TvJs4PXA4jbz3gNY3t9Hkl2BdwH7V9UewMkjXOpC4O1VtTu9MO2fsc+sqn2AtzL+mfwC4ISq\n2iXJC4DDgJe0WmcCR7SVgoXAy6tqT2DFKDX2+3Abh92AWcDv9B3brPV/MnBu2/dXwNXtPvYHPpBk\n83HeiyRpCnR1iXttDgR2T3J4+3gWMA+4DTgvySbAFVW1fNh5+wOXVdUPAKrqof6DSWYBs6vq+rbr\nAuCyviaXt7+XAXPHWfOSqvp22z6A3hcWS9uEdwvgO8DPgOcDN7f9mwI3jtHvy5OcAmwObNtq+3w7\ndglAVV2XZPskW9Mbu1cmWdjabA7suLYLJDmO3goGM56y3UA3K0ladxtEQCd5DrAaeBAIcFJVLR6h\n3b7AwcD5ST5YVRdOYhm/aH+vZvzj9nDfdoDzquov+xskOYze7PbIQTpMsiVwNrBnVT2Q5DR6gTuk\nhp1S7dqHVtU3h/U1akhX1TnAOQCbzZk3vE9J0nrS+SXuJNsBi4Czq6qAxcBb2kyZJM9NslWSZwHf\nr6qP0VvS3XNYV9cBf5Dk6e28p/UfrKpVwI/6ni8fCVzP5LsWeE3fc/Gnt4C8Gfit9sUI7Z7mraWf\nLYDHgR8k2QZ49bDjr2397EdvXB6mN3YnDTVI8sLJuSVJ0mTr6gx6iyTLgU2Ax4CLgA+2Y+fSW2L+\nSnsp6j+AQ4H9gFOSPAr8FHjCt05V1Z1J3gtcn2Q18FXgjcOuezSwqM1O7wWOmewbq6qVSU4Frm0v\nhz0KHF9VtyU5Frg0yaat+TuAr4/Szw+TXADcBXwP+PKwJo+2MZzRdx+nAmcmWUnvi7NvAIdM4u1J\nkiZJepNSaWybzZlXc44+c7rLkLQBuO/0g6e7hM5IsqyqFoz3vM4vcUuS9GRkQEuS1EEGtCRJHWRA\nS5LUQQa0JEkdZEBLktRBBrQkSR1kQEuS1EEGtCRJHWRAS5LUQQa0JEkdZEBLktRBBrQkSR1kQEuS\n1EEGtCRJHWRAS5LUQTOnuwBtOHbbYRZL/SXskjQlnEFLktRBBrQkSR1kQEuS1EEGtCRJHWRAS5LU\nQQa0JEkdZEBLktRBBrQkSR1kQEuS1EGpqumuQRuIJD8B7p7uOjpiW+AH011ERzgWazgWazgWazyv\nqrYZ70n+qE+Nx91VtWC6i+iCJEsdix7HYg3HYg3HYo0kSydynkvckiR1kAEtSVIHGdAaj3Omu4AO\ncSzWcCzWcCzWcCzWmNBY+JKYJEkd5AxakqQOMqD1S5L8TpK7k3wjycIRjifJWe34iiR7TkedU2GA\nsXhDG4OVSW5Ossd01Lm+jTUOfe32TvJYksOnsr6pNMhYJNkvyfIkdya5fqprnCoD/P8xK8k/J7m9\njcUx01HnVEhyXpIHk9wxyvHxf96sKv/457/+ADOAbwLPATYFbgeeP6zNQcDngQAvAr483XVP41i8\nBHhq237lxjgWg4xDX7vrgKuAw6e77mn8b2I2cBewY/t4++muexrH4h3A+9r2dsBDwKbTXft6Go99\ngT2BO0Y5Pu7Pm86gNdw+wDeq6t6q+k/gk8Ahw9ocAlxYPbcAs5PMmepCp8CYY1FVN1fVj9qHtwDP\nnOIap8Ig/00AnAT8E/DgVBY3xQYZi9cDl1fVtwGqamMdj0HGooBtkgTYml5APza1ZU6NqvoSvfsb\nzbg/bxrQGm4H4Dt9H9/f9o23zcZgvPd5LL2vkDc2Y45Dkh2Aw4D/PYV1TYdB/pt4LvDUJF9MsizJ\nUVNW3dQaZCzOBnYBvgusBE6uqsenprzOGffnTX+SmDQJkvw2vYB+6XTXMk3OBN5eVY/3JktPajOB\nvYCXA1sAS5LcUlX3TG9Z0+IVwHJgf2An4JokN1TV/5vesjYMBrSGewD4tb6Pn9n2jbfNxmCg+0yy\nO3Au8Mqq+uEU1TaVBhmHBcAnWzhvCxyU5LGqumJqSpwyg4zF/cAPq+ph4OEkXwL2ADa2gB5kLI4B\nTq/eQ9hvJPkW8OvArVNTYqeM+/OmS9wa7jZgXpJnJ9kUOAL47LA2nwWOam8lvghYVVXfm+pCp8CY\nY5FkR+By4MiNeIY05jhU1bOram5VzQU+BZywEYYzDPb/x2eAlyaZmWRL4DeAr01xnVNhkLH4Nr2V\nBJL8KvA84N4prbI7xv150xm0nqCqHktyIrCY3lua51XVnUmOb8cX0XtL9yDgG8DP6H2VvNEZcCz+\nCng68JE2e3ysNrJfEDDgODwpDDIWVfW1JFcDK4DHgXOrasRvvdmQDfjfxf8Ezk+ykt7by2+vqo3y\nN1wluQTYD9g2yf3Au4FNYOKfN/1JYpIkdZBL3JIkdZABLUlSBxnQkiR1kAEtSVIHGdCSJHWQAS1J\nUgcZ0JIkdZABLUlSB/1/VPL8IPMXficAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x219e5418a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(classifier_accuracy_comparisons)), list(classifier_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(classifier_accuracy_comparisons)), list(classifier_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Through SuperLearnerClassifier Architectures & Parameters (Task 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a grid search experiment to detemrine the optimal architecture and hyper-parameter values for the SuperLearnClasssifier for the MNIST Fashion classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_models': ['RF', 'NB', 'KNN'], 'criteria': 'label', 'number_of_models': 5, 'stack_model': 'CART'}\n",
      "Score for Best parameters set found on development set:\n",
      "0.792380952381\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to search\n",
    "param_grid = [\n",
    " {'criteria': ['probability','label'], \n",
    "  'base_models':[['LR','CART','NB'],['MLP','RF','SVC'],['MLP','CART','LR'],['RF', 'NB', 'KNN']], \n",
    "  'stack_model':['CART','LR'] ,\n",
    "  'number_of_models':list(range(5, 11))\n",
    " }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(SuperLearnerClassifier(), param_grid, cv=cv_folds)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "print(\"Score for Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the model selected by the grid search on a hold-out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.87      0.80        75\n",
      "          1       0.99      0.87      0.92        92\n",
      "          2       0.64      0.72      0.68       115\n",
      "          3       0.81      0.74      0.77        91\n",
      "          4       0.63      0.71      0.67        90\n",
      "          5       0.89      0.95      0.92        87\n",
      "          6       0.68      0.47      0.56        85\n",
      "          7       0.88      0.87      0.88        87\n",
      "          8       0.88      0.95      0.91        76\n",
      "          9       0.94      0.88      0.91       102\n",
      "\n",
      "avg / total       0.80      0.80      0.80       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "      <td>130</td>\n",
       "      <td>83</td>\n",
       "      <td>102</td>\n",
       "      <td>93</td>\n",
       "      <td>59</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1    2   3    4   5   6   7   8   9  All\n",
       "True                                                    \n",
       "0          65   0    3   1    2   0   3   0   1   0   75\n",
       "1           1  80    2   8    1   0   0   0   0   0   92\n",
       "2           2   0   83   0   17   0  11   0   2   0  115\n",
       "3           9   1    5  67    6   0   2   0   1   0   91\n",
       "4           0   0   18   5   64   0   3   0   0   0   90\n",
       "5           0   0    0   0    0  83   0   3   0   1   87\n",
       "6          11   0   16   2   12   0  40   0   4   0   85\n",
       "7           0   0    0   0    0   6   0  76   0   5   87\n",
       "8           0   0    3   0    0   1   0   0  72   0   76\n",
       "9           0   0    0   0    0   3   0   7   2  90  102\n",
       "All        88  81  130  83  102  93  59  86  82  96  900"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the hold out test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       8    ...          103        87        56         0         0   \n",
       "1       0    ...           34         0         0         0         0   \n",
       "2      99    ...            0         0         0         0        63   \n",
       "3       0    ...          137       126       140         0       133   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2        53        31         0         0         0  \n",
       "3       224       222        56         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_dataset[test_dataset.columns[1:]]\n",
    "test_Y = np.array(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_X/255 # normalize the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.817\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.80      0.75      1000\n",
      "          1       0.99      0.92      0.96      1000\n",
      "          2       0.71      0.73      0.72      1000\n",
      "          3       0.87      0.80      0.83      1000\n",
      "          4       0.68      0.81      0.74      1000\n",
      "          5       0.88      0.91      0.89      1000\n",
      "          6       0.67      0.46      0.55      1000\n",
      "          7       0.89      0.85      0.87      1000\n",
      "          8       0.89      0.96      0.92      1000\n",
      "          9       0.91      0.92      0.92      1000\n",
      "\n",
      "avg / total       0.82      0.82      0.81     10000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>804</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>921</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>735</td>\n",
       "      <td>4</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>797</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>813</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>26</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>849</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>961</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>923</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1130</td>\n",
       "      <td>928</td>\n",
       "      <td>1042</td>\n",
       "      <td>921</td>\n",
       "      <td>1203</td>\n",
       "      <td>1034</td>\n",
       "      <td>686</td>\n",
       "      <td>955</td>\n",
       "      <td>1085</td>\n",
       "      <td>1016</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0    1     2    3     4     5    6    7     8     9    All\n",
       "True                                                                    \n",
       "0           804    0    22   50    13     2   75    1    33     0   1000\n",
       "1            19  921    16   27     0     0   11    0     6     0   1000\n",
       "2            18    0   735    4   163     0   57    0    23     0   1000\n",
       "3            78    6    39  797    59     0   18    0     3     0   1000\n",
       "4             7    0    99   14   813     1   60    0     6     0   1000\n",
       "5             4    0     0    0     1   905    0   58     4    28   1000\n",
       "6           197    0   119   26   149     2  462    0    45     0   1000\n",
       "7             0    0     0    0     0    87    0  849     0    64   1000\n",
       "8             3    1    11    3     5     5    3    7   961     1   1000\n",
       "9             0    0     1    0     0    32    0   40     4   923   1000\n",
       "All        1130  928  1042  921  1203  1034  686  955  1085  1016  10000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(test_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_Y, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(test_Y), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Impact of Adding Original Descriptive Features at the Stack Layer (Task 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the impact of adding original descriptive features at the stack layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with_descriptive_feature': 0.76888888888888884,\n",
       " 'without_descriptive_feature': 0.79333333333333333}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_accuracy_comparisons = dict()\n",
    "# train the Super learner without the descriptive feature\n",
    "params = {'base_models': ['RF', 'NB', 'KNN'], 'criteria': 'label', 'number_of_models': 5, 'stack_model': 'CART'} # best_params from GridSearchCV\n",
    "clf = SuperLearnerClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_without_desc_feature = clf.predict(X_test)\n",
    "\n",
    "# train the Super learner with the descriptive feature\n",
    "clf_desc_feature = SuperLearnerClassifier(stack_input=True, **params)\n",
    "clf_desc_feature.fit(X_train, y_train)\n",
    "y_pred_desc_feature = clf_desc_feature.predict(X_test)\n",
    "\n",
    "# measure accuracy of the model trained without descriptive feature\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_without_desc_feature) \n",
    "classifier_accuracy_comparisons['without_descriptive_feature'] = accuracy\n",
    "\n",
    "# measure accuracy of the model trained with the descriptive feature\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_desc_feature)\n",
    "classifier_accuracy_comparisons['with_descriptive_feature'] = accuracy\n",
    "\n",
    "# Print performance details\n",
    "display(classifier_accuracy_comparisons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding original feature should have increased the performance. However, here there is a slight decresase. \n",
    "This is probably due the reason that, MNIST data set has many descriptive features and the sample dataset \n",
    "we are using is not enough with respect to the number of features available in the trainig set.\n",
    "Thus, because of curse of dimensionality the accuracy is slightly decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAD8CAYAAABqxe1QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZI6838ap7KfwG90xwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21987353ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(classifier_accuracy_comparisons)), list(classifier_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(classifier_accuracy_comparisons)), list(classifier_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Ensemble Model (Task 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an analysis to investigate the strength of the base estimators and the strengths of the correlations between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the super learner with all possible base learners to investigate the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(base_models=['LR', 'KNN', 'CART', 'SVC', 'NB', 'RF', 'MLP'],\n",
       "            criteria='label', number_of_models=7, stack_input=False,\n",
       "            stack_model='CART')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a SuperLearner object to check the diversity of the base_learners\n",
    "clf = SuperLearnerClassifier( base_models=['LR','KNN','CART','SVC','NB','RF','MLP'], number_of_models=7)\n",
    "\n",
    "#fit the model using x_train and y_train\n",
    "clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' style='font-style:italic'>Diversity measures of the base models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the diversity measure\n",
    "corr_coeff , q_stat, disagreement_measure = clf.get_diversity_base_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "      <th>CART</th>\n",
       "      <th>SVC</th>\n",
       "      <th>NB</th>\n",
       "      <th>RF</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CART</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR   KNN  CART   SVC    NB    RF   MLP\n",
       "LR    1.00  0.51  0.44  0.60  0.31  0.60  0.55\n",
       "KNN   0.51  1.00  0.40  0.53  0.28  0.60  0.44\n",
       "CART  0.44  0.40  1.00  0.48  0.29  0.50  0.34\n",
       "SVC   0.60  0.53  0.48  1.00  0.35  0.79  0.45\n",
       "NB    0.31  0.28  0.29  0.35  1.00  0.35  0.26\n",
       "RF    0.60  0.60  0.50  0.79  0.35  1.00  0.44\n",
       "MLP   0.55  0.44  0.34  0.45  0.26  0.44  1.00"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corr_coeff\n",
    "round(corr_coeff,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High value means high correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#q_statistics\n",
    "round(q_stat,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High value means high correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "      <th>CART</th>\n",
       "      <th>SVC</th>\n",
       "      <th>NB</th>\n",
       "      <th>RF</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CART</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LR   KNN  CART   SVC    NB    RF   MLP\n",
       "LR    0.00  0.17  0.23  0.15  0.34  0.13  0.15\n",
       "KNN   0.17  0.00  0.25  0.18  0.35  0.15  0.21\n",
       "CART  0.23  0.25  0.00  0.22  0.35  0.20  0.27\n",
       "SVC   0.15  0.18  0.22  0.00  0.32  0.08  0.21\n",
       "NB    0.34  0.35  0.35  0.32  0.00  0.32  0.36\n",
       "RF    0.13  0.15  0.20  0.08  0.32  0.00  0.20\n",
       "MLP   0.15  0.21  0.27  0.21  0.36  0.20  0.00"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#disagreement_measure\n",
    "round(disagreement_measure,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High value means high Disagreement. That means low values indict high level of correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' style='font-style:italic'>Predictive power of the base models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies of the base models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CART': 0.68533333333333335,\n",
       " 'KNN': 0.75600000000000001,\n",
       " 'LR': 0.79933333333333334,\n",
       " 'MLP': 0.78666666666666663,\n",
       " 'NB': 0.55600000000000005,\n",
       " 'RF': 0.78133333333333332,\n",
       " 'SVC': 0.74333333333333329}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracies of the base models')\n",
    "clf.get_predictive_power_base_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------LR---------------------------------------\n",
      "\n",
      "\n",
      "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
      "True                                                             \n",
      "0          115    2    3   12    1    0   11    0    2    0   146\n",
      "1            0  130    2    5    2    0    0    0    0    0   139\n",
      "2            2    0  119    2   26    0   13    0    4    0   166\n",
      "3            4    3    1  128    6    0    9    0    0    0   151\n",
      "4            1    0   20   11  129    0    9    0    3    0   173\n",
      "5            0    0    0    0    0  113    0   16    2   10   141\n",
      "6           25    0   22   10   22    0   62    0    7    0   148\n",
      "7            0    0    0    0    0    8    0  112    0    7   127\n",
      "8            0    0    2    2    3    0    1    1  145    0   154\n",
      "9            0    0    0    1    0    1    0    5    2  146   155\n",
      "All        147  135  169  171  189  122  105  134  165  163  1500\n",
      "\n",
      "\n",
      "--------------------------------KNN---------------------------------------\n",
      "\n",
      "\n",
      "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
      "True                                                             \n",
      "0          130    0    3    4    1    0    7    0    1    0   146\n",
      "1            4  129    3    3    0    0    0    0    0    0   139\n",
      "2           12    0  118    1   20    0   12    0    3    0   166\n",
      "3           17    3    3  111    7    0   10    0    0    0   151\n",
      "4            4    0   39   13   89    0   28    0    0    0   173\n",
      "5            1    0    1    0    2  105    1   21    0   10   141\n",
      "6           38    1   31    4   14    0   57    0    3    0   148\n",
      "7            0    0    0    0    0    5    0  112    0   10   127\n",
      "8            1    0    4    4    1    0    7    3  134    0   154\n",
      "9            0    0    0    0    1    3    0    2    0  149   155\n",
      "All        207  133  202  140  135  113  122  138  141  169  1500\n",
      "\n",
      "\n",
      "--------------------------------CART---------------------------------------\n",
      "\n",
      "\n",
      "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
      "True                                                             \n",
      "0          108    0    6   12    2    0   16    0    2    0   146\n",
      "1            0  109    2   25    1    0    2    0    0    0   139\n",
      "2            1    1  109    1   31    0   19    0    4    0   166\n",
      "3           12    6    7  115    1    3    4    0    1    2   151\n",
      "4            3    2   25   22   87    0   30    0    4    0   173\n",
      "5            1    0    1    2    0  103    1   19    3   11   141\n",
      "6           33    1   14    9   30    0   51    0   10    0   148\n",
      "7            0    0    0    0    0   20    0   92    0   15   127\n",
      "8            1    1    7    4    1   12    5    1  122    0   154\n",
      "9            0    0    0    2    0    8    2   10    1  132   155\n",
      "All        159  120  171  192  153  146  130  122  147  160  1500\n",
      "\n",
      "\n",
      "--------------------------------SVC---------------------------------------\n",
      "\n",
      "\n",
      "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
      "True                                                            \n",
      "0          112    0    2   21    1    3   6    0    1    0   146\n",
      "1            1  120    4   12    1    1   0    0    0    0   139\n",
      "2            3    0  106    1   33    3  17    0    3    0   166\n",
      "3            4    0    0  134    5    0   8    0    0    0   151\n",
      "4            1    0   27   19  107    2  15    0    2    0   173\n",
      "5            0    0    0    0    0  120   0   16    0    5   141\n",
      "6           30    0   18   14   40    1  40    0    5    0   148\n",
      "7            0    0    0    0    0   10   0  107    0   10   127\n",
      "8            0    0    6    6    0    8   3    2  129    0   154\n",
      "9            0    0    0    0    0    6   0    9    0  140   155\n",
      "All        151  120  163  207  187  154  89  134  140  155  1500\n",
      "\n",
      "\n",
      "--------------------------------NB---------------------------------------\n",
      "\n",
      "\n",
      "Predicted    0    1   2    3    4   5   6    7    8    9   All\n",
      "True                                                          \n",
      "0           95   14   2   12   14   0   3    0    6    0   146\n",
      "1            0  130   3    6    0   0   0    0    0    0   139\n",
      "2            0    5  36   12   99   0  11    0    3    0   166\n",
      "3            1   74   0   69    6   0   1    0    0    0   151\n",
      "4            0   12  12   32  117   0   0    0    0    0   173\n",
      "5            0    0   0    1    0  51   2   71    6   10   141\n",
      "6           13    9  14   21   73   0   8    0   10    0   148\n",
      "7            0    0   0    0    0   8   0  115    2    2   127\n",
      "8            0    0   9   17   21   0   7    0  100    0   154\n",
      "9            0    0   1    1    0   7   3   28    2  113   155\n",
      "All        109  244  77  171  330  66  35  214  129  125  1500\n",
      "\n",
      "\n",
      "--------------------------------RF---------------------------------------\n",
      "\n",
      "\n",
      "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
      "True                                                            \n",
      "0          118    0    4   18    0    1   3    0    2    0   146\n",
      "1            1  125    4    8    1    0   0    0    0    0   139\n",
      "2            2    0  116    1   33    0   9    0    5    0   166\n",
      "3            3    0    1  138    7    0   2    0    0    0   151\n",
      "4            0    1   33   18  112    0   8    0    1    0   173\n",
      "5            0    0    0    0    0  127   0    9    0    5   141\n",
      "6           31    1   20   14   35    0  38    0    9    0   148\n",
      "7            0    0    0    0    0    7   0  109    1   10   127\n",
      "8            0    0    0    4    0    1   1    1  147    0   154\n",
      "9            0    0    0    1    0    5   0    7    0  142   155\n",
      "All        155  127  178  202  188  141  61  126  165  157  1500\n",
      "\n",
      "\n",
      "--------------------------------MLP---------------------------------------\n",
      "\n",
      "\n",
      "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
      "True                                                             \n",
      "0          116    1    3    8    0    0   17    0    1    0   146\n",
      "1            1  129    4    5    0    0    0    0    0    0   139\n",
      "2            4    0  118    1   25    0   15    0    3    0   166\n",
      "3            7    6    4  115   10    0    8    0    1    0   151\n",
      "4            0    0   21    9  122    0   17    0    4    0   173\n",
      "5            0    0    0    0    0  114    0   14    3   10   141\n",
      "6           25    2   20    6   20    0   71    0    4    0   148\n",
      "7            0    0    0    0    0    6    0  115    0    6   127\n",
      "8            0    0    4    1    3    1    6    0  139    0   154\n",
      "9            0    0    0    0    0    5    0    8    1  141   155\n",
      "All        153  138  174  145  180  126  134  137  156  157  1500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf = clf.get_confusion_matrix_base_models()\n",
    "for model in cf:\n",
    "    print('--------------------------------'+str(model)+'---------------------------------------')\n",
    "    print('\\n')\n",
    "    print(cf[model])\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
